<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>A Computational Framework to Study the Impact of VPA Exposure on Chick Vocal Repertoire</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 0;
            background-color: #f4f4f9;
        }
        .paper-info, .abstract {
            margin: 20px;
            padding: 20px;
            background-color: #fff;
            border-radius: 8px;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        }
        h3 {
            color: #005f73;
        }
        .authors {
            font-style: italic;
        }
        .journal-info {
            font-weight: bold;
        }
    </style>
</head>
<body>

    <div class="paper-info">
        <h3>Title</h3>
        <p><strong>A Computational Framework to Study the Impact of VPA Exposure on Chick Vocal Repertoire</strong></p>

        <h3>Authors</h3>
        <p class="authors">Antonella Torrisi¹, Elisabetta Versace²*, Emmanouil Benetos³*, Paola Sgadò⁴*</p>
        <p style="font-size: 0.9em; color: #6c757d; margin-top: 5px;">
            ¹, ², ³ Queen Mary University of London, UK<br>
            ⁴ University of Trento, Italy<br>
            *Corresponding author
        </p>

        <h3>Journal/Conference</h3>
        <p class="journal-info">Behavioral Neuroscience & Animal Communication</p>

        <h3>Publication Date</h3>
        <p>2025</p>
    </div>

    <div class="abstract">
        <h3>Abstract</h3>
        <p>Traditional approaches to the analysis of chick vocalisations rely on subjective manual annotation, limiting reproducibility and scalability. We present a computational and analytical framework for the automated detection, feature extraction, and unsupervised classification of chick (Gallus gallus) spontaneous vocalisations during the first day of life post-hatching. We extracted 20 acoustic features spanning temporal, frequency, and energy domains and implemented unsupervised call categorisation. Through this method, we identified a three-cluster division of chicks’ natural vocal repertoire during individual explorations.</p>
        <p>After validating this framework, we used it to compare vocalisations from chicks prenatally exposed to Valproic Acid (VPA)—a compound that increases the risk of autism in humans—with those of control subjects. The statistical and cluster analyses revealed significant differences between groups. VPA-exposed chicks produced shorter and less variable calls, with faster attack times and reduced variability in frequency and intensity. This finding suggests that vocal alterations can be used as markers for developmental disruption.</p>
        <p>Overall, we identify specific vocal differences in VPA-exposed versus control chicks. This may reflect communication deficits similar to those observed in neurodevelopmental disorders, confirming chicks as a model for studying typical and atypical vocalisations. Moreover, our innovative approach advances general methodology by introducing a reproducible computational pipeline for animal vocalisation analysis. This automation reduces both manual workload and human annotation bias, paving the way for large-scale studies on the development of vocal communication.</p>
    </div>

    <h3>Keywords</h3>
    <p>Chick vocalisations, Computational bioacoustics, Valproic acid, Unsupervised clustering, Neurodevelopmental disorders, Automated detection, Animal communication, Acoustic feature extraction</p>

</body>
</html>
